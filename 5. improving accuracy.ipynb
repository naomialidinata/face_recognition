{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Accuracy\n",
    "\n",
    "It's not always the case that you have the perfect dataset and the perfect test subjects. Imagine a situation where you only have one picture/subject in your dataset, and you have to find the face of one person from thousands of images. The results can very quickly get messy. In this notebook, I will show a way to tackle this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_vggface as kv\n",
    "import modules.utils as utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a FacePreprocess instance.\n",
    "from modules.FacePreprocess import FacePreprocess\n",
    "ssd_model = r'./models/ssd/deploy.prototxt.txt'\n",
    "ssd_weights = r'./models/ssd/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "processor = FacePreprocess(ssd_model, ssd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facial embedding model you want to use\n",
    "model = kv.VGGFace(\n",
    "    model='resnet50', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='avg'\n",
    ")\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "5 images processed.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================\n",
    "# Compute Embeddings\n",
    "id_list = pd.DataFrame(columns=['name', 'file'])\n",
    "embeddings = []\n",
    "for id in os.listdir('./dataset/train/'):\n",
    "    folder = './dataset/train/{}/'.format(id)\n",
    "    \n",
    "    # use img_1 for every subject\n",
    "    file = 'img_1.jpg'\n",
    "    try:\n",
    "        filepath = os.path.join(folder, file)\n",
    "        processed_img = processor.preproc(cv2.imread(filepath))[0][0]\n",
    "        embedding = model.predict(utils.resize(processed_img, input_size), verbose=False)[0,:]\n",
    "\n",
    "        id_list.loc[len(id_list.index)] = [id, filepath]\n",
    "        embeddings.append(embedding)\n",
    "    except:\n",
    "        print('Failed to process/predict {}'.format(filepath))\n",
    "print('='*10 + '\\n{} images processed.'.format(len(embeddings)))\n",
    "\n",
    "# ==========================================================================\n",
    "# Initialize nmslib\n",
    "index_time_params = {'M': 15, 'indexThreadQty': 4, 'efConstruction': 100, 'post' : 0}\n",
    "\n",
    "# l2 dist.\n",
    "index_l2 = nmslib.init(\n",
    "    method = 'hnsw', # hierarchical navigable small world graph\n",
    "    space = 'l2', # euclidean\n",
    "    data_type = nmslib.DataType.DENSE_VECTOR\n",
    ") \n",
    "index_l2.addDataPointBatch(embeddings)\n",
    "index_l2.createIndex(index_time_params)\n",
    "\n",
    "# cosine simil.\n",
    "index_cos = nmslib.init(\n",
    "    method = 'hnsw', # hierarchical navigable small world graph\n",
    "    space = 'cosinesimil', # cosine\n",
    "    data_type = nmslib.DataType.DENSE_VECTOR\n",
    ") \n",
    "index_cos.addDataPointBatch(embeddings)\n",
    "index_cos.createIndex(index_time_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this model on `./dataset/test/test_2/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dist.</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>Avg. Confidence</th>\n",
       "      <th>Std. Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>174</td>\n",
       "      <td>80</td>\n",
       "      <td>6621.646484</td>\n",
       "      <td>763.319153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>0.322694</td>\n",
       "      <td>0.038077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "      <td>8066.996094</td>\n",
       "      <td>1063.527222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333638</td>\n",
       "      <td>0.036382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>211</td>\n",
       "      <td>7</td>\n",
       "      <td>6007.014160</td>\n",
       "      <td>985.237366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>0.244937</td>\n",
       "      <td>0.048893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>91</td>\n",
       "      <td>116</td>\n",
       "      <td>9710.950195</td>\n",
       "      <td>1389.878418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>93</td>\n",
       "      <td>114</td>\n",
       "      <td>0.418397</td>\n",
       "      <td>0.064799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>320</td>\n",
       "      <td>94</td>\n",
       "      <td>7113.110840</td>\n",
       "      <td>1012.918640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>340</td>\n",
       "      <td>74</td>\n",
       "      <td>0.327458</td>\n",
       "      <td>0.094571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     Model        Dist.  True  False  Avg. Confidence  \\\n",
       "0   irene  resnet50           l2   174     80      6621.646484   \n",
       "1   irene  resnet50  cosinesimil   151    103         0.322694   \n",
       "2     joy  resnet50           l2   540      3      8066.996094   \n",
       "3     joy  resnet50  cosinesimil   542      1         0.333638   \n",
       "4  seulgi  resnet50           l2   211      7      6007.014160   \n",
       "5  seulgi  resnet50  cosinesimil   213      5         0.244937   \n",
       "6   wendy  resnet50           l2    91    116      9710.950195   \n",
       "7   wendy  resnet50  cosinesimil    93    114         0.418397   \n",
       "8    yeri  resnet50           l2   320     94      7113.110840   \n",
       "9    yeri  resnet50  cosinesimil   340     74         0.327458   \n",
       "\n",
       "   Std. Confidence  \n",
       "0       763.319153  \n",
       "1         0.038077  \n",
       "2      1063.527222  \n",
       "3         0.036382  \n",
       "4       985.237366  \n",
       "5         0.048893  \n",
       "6      1389.878418  \n",
       "7         0.064799  \n",
       "8      1012.918640  \n",
       "9         0.094571  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = pd.DataFrame(\n",
    "    columns = ['ID', 'Model', 'Dist.', 'True', 'False', 'Avg. Confidence', 'Std. Confidence'], \n",
    ")\n",
    "\n",
    "for file in os.listdir('./dataset/test/test_2/'):\n",
    "    video_path = './dataset/test/test_2/'+file\n",
    "    id = file.replace('.mp4', '')\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = {\n",
    "        'l2':{'True': 0, 'False':0, 'conf':[]},\n",
    "        'cosine':{'True': 0, 'False':0, 'conf':[]},\n",
    "    }\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        try:\n",
    "            img = frame.copy()\n",
    "            faces = processor.preproc(img)\n",
    "\n",
    "            if len(faces)>0:\n",
    "                for face in faces:\n",
    "                    # target embeddings\n",
    "                    target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                    target = np.array(target, dtype='f')\n",
    "                    target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                    # l2\n",
    "                    neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['l2']['True'] += 1\n",
    "                        count['l2']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['l2']['False'] += 1\n",
    "\n",
    "                    # cosinesimil\n",
    "                    neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['cosine']['True'] += 1\n",
    "                        count['cosine']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['cosine']['False'] += 1\n",
    "        except:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'l2', count['l2']['True'], count['l2']['False'], np.average(count['l2']['conf']), np.std(count['l2']['conf'])]\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'cosinesimil', count['cosine']['True'], count['cosine']['False'], np.average(count['cosine']['conf']), np.std(count['cosine']['conf'])]\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.75 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(results_all['True'])/(np.sum(results_all['True'])+np.sum(results_all['False']))*100\n",
    "print('Accuracy: {:0.2f} %'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output/real_time_face_recognition/results.xlsx'\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:  \n",
    "    results_all.to_excel(writer, sheet_name='single sample', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with only one image/subject, the accuracy isn't as great (For reference, with 5 images/subject the accuracy is 85.45%). In this case we only have 5 subjects in our dataset, so the results aren't as bad. But when you have more people in your dataset, the results will only get worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Add confidence threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Double verification\n",
    "\n",
    "For this method, we will use both distance models at once. If both models return the same ID, we'll add it to the tally, otherwise we'll count it as unknown.\n",
    "\n",
    "![fig](./assets/fig3.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8d291e76e21ac4114bb3934f79c9cd83293577e20f5f8f5d14a21fd0b06f79d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
