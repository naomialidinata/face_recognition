{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Face Recognition\n",
    "\n",
    "Let's apply all our previous knowledge into a real-time face recognition. We will try to continuously perform facial recognition on a video stream. In this example I will use an offline video as input, but in reality you can apply it using a webcam, a cctv's live camera feed, etc! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_vggface as kv\n",
    "import modules.utils as utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a FacePreprocess instance.\n",
    "from modules.FacePreprocess import FacePreprocess\n",
    "ssd_model = r'./models/ssd/deploy.prototxt.txt'\n",
    "ssd_weights = r'./models/ssd/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "processor = FacePreprocess(ssd_model, ssd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facial embedding model you want to use\n",
    "model = kv.VGGFace(\n",
    "    model='resnet50', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='avg'\n",
    ")\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our nmslib index tree\n",
    "nmslib_path = './output/large_scale_face_recognition/'\n",
    "\n",
    "# load id_list\n",
    "id_list = pd.read_csv(nmslib_path + '/IDlist.csv')\n",
    "\n",
    "# Euclidean distance\n",
    "index_l2 = nmslib.init(method='hnsw', space='l2', data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "index_l2.loadIndex(nmslib_path + 'resnet50_index_l2.bin')\n",
    "\n",
    "# Cosine similarity\n",
    "index_cos = nmslib.init(method='hnsw', space='cosinesimil', data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "index_cos.loadIndex(nmslib_path + 'resnet50_index_cos.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier evaluation, we will use a video with only one of the subjects (joy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original clip from https://youtu.be/Ia3x_X_OX58?si=aA5GdMpRGcCar2xF \n",
    "video_path = './dataset/test/test_2/joy.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture frame-by-frame\n",
    "\n",
    "We will use openCV's `VideoCapture` which will return the video frame by frame to try and recognize the person in the video. To test the accuracy, we will keep track of the predictions. We will also output a video showing the prediction results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    columns = ['count', 'irene', 'seulgi', 'wendy', 'joy', 'yeri'], \n",
    "    index = ['l2', 'cosinesimil']\n",
    ")\n",
    "results.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count` will keep track the number of predictions made, and the columns for the other subjects will count how many times where they predicted as the person in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read: https://docs.opencv.org/3.4/dd/d9e/classcv_1_1VideoWriter.html#afec93f94dc6c0b3e28f4dd153bc5a7f0 \n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean dist. `l2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 16:43:37.693285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "dist = 'l2'\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# setup video writer\n",
    "vid = './output/real_time_face_recognition/resnet50_l2.mp4'\n",
    "out = cv2.VideoWriter() \n",
    "out.open(vid, fourcc, 24.0, (1920, 1080), True) # frame rate, frame size (w, h) must be same as input\n",
    "\n",
    "# read video frame-by-frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        img = frame.copy()\n",
    "        faces = processor.preproc(img)\n",
    "\n",
    "        if len(faces)>0:\n",
    "            for face in faces:\n",
    "                results['count'][dist] += 1\n",
    "\n",
    "                # target embeddings\n",
    "                target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                target = np.array(target, dtype='f')\n",
    "                target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                # predict\n",
    "                neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                \n",
    "                # results\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name][dist] += 1\n",
    "\n",
    "            # add video frame\n",
    "            top, bottom, left, right = face[1][0], face[1][1], face[1][2], face[1][3]\n",
    "            cv2.putText(frame, str(name), (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 1) \n",
    "        out.write(frame)\n",
    "\n",
    "        # if you unblock this part a window will pop up and show the frames, but only works if you run with .py \n",
    "        # On jupyter notebooks the window will crash after the loop ends and you have to restart the kernel\n",
    "        # cv2.imshow(\"frame\", frame)\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine simil. `cosinesimil`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>irene</th>\n",
       "      <th>seulgi</th>\n",
       "      <th>wendy</th>\n",
       "      <th>joy</th>\n",
       "      <th>yeri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosinesimil</th>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count  irene  seulgi  wendy  joy  yeri\n",
       "l2             542      0       0      0  542     0\n",
       "cosinesimil    542      0       0      0  542     0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = 'cosinesimil'\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# setup video writer\n",
    "vid = './output/real_time_face_recognition/resnet50_cosinesimil.mp4'\n",
    "out = cv2.VideoWriter() \n",
    "out.open(vid, fourcc, 24.0, (1920, 1080), True) # frame rate, frame size (w, h) must be same as input\n",
    "\n",
    "# read video frame-by-frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        img = frame.copy()\n",
    "        faces = processor.preproc(img)\n",
    "\n",
    "        if len(faces)>0:\n",
    "            for face in faces:\n",
    "                results['count'][dist] += 1\n",
    "\n",
    "                # target embeddings\n",
    "                target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                target = np.array(target, dtype='f')\n",
    "                target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                # predict\n",
    "                neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                \n",
    "                # results\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name][dist] += 1\n",
    "\n",
    "            # add video frame\n",
    "            top, bottom, left, right = face[1][0], face[1][1], face[1][2], face[1][3]\n",
    "            cv2.putText(frame, str(name), (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 1) \n",
    "        out.write(frame)\n",
    "\n",
    "        # if you unblock this part a window will pop up and show the frames, but only works if you run with .py \n",
    "        # On jupyter notebooks the window will crash after the loop ends and you have to restart the kernel\n",
    "        # cv2.imshow(\"frame\", frame)\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test video only contains Joy, so it looks like the prediction results are correct. Using both L2 and Cosine distance achieve similar results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full test\n",
    "\n",
    "Let's benchmark the other videos in the test set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.DataFrame(\n",
    "    columns = ['ID', 'Model', 'Dist.', 'True', 'False', 'Avg. Distance', 'Std. Distance'], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dist.</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>Avg. Distance</th>\n",
       "      <th>Std. Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>307</td>\n",
       "      <td>106</td>\n",
       "      <td>5638.690430</td>\n",
       "      <td>960.973389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>383</td>\n",
       "      <td>30</td>\n",
       "      <td>0.262753</td>\n",
       "      <td>0.084763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "      <td>5110.183105</td>\n",
       "      <td>852.788635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205780</td>\n",
       "      <td>0.043738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>5322.081543</td>\n",
       "      <td>799.970825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>165</td>\n",
       "      <td>90</td>\n",
       "      <td>0.269541</td>\n",
       "      <td>0.040678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>8033.906250</td>\n",
       "      <td>1106.328613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>146</td>\n",
       "      <td>62</td>\n",
       "      <td>0.344040</td>\n",
       "      <td>0.052192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>5262.923340</td>\n",
       "      <td>1023.091980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238197</td>\n",
       "      <td>0.039151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     Model        Dist.  True  False  Avg. Distance  Std. Distance\n",
       "0    yeri  resnet50           l2   307    106    5638.690430     960.973389\n",
       "1    yeri  resnet50  cosinesimil   383     30       0.262753       0.084763\n",
       "2  seulgi  resnet50           l2   217      2    5110.183105     852.788635\n",
       "3  seulgi  resnet50  cosinesimil   217      2       0.205780       0.043738\n",
       "4   irene  resnet50           l2   158     97    5322.081543     799.970825\n",
       "5   irene  resnet50  cosinesimil   165     90       0.269541       0.040678\n",
       "6   wendy  resnet50           l2   136     72    8033.906250    1106.328613\n",
       "7   wendy  resnet50  cosinesimil   146     62       0.344040       0.052192\n",
       "8     joy  resnet50           l2   542      0    5262.923340    1023.091980\n",
       "9     joy  resnet50  cosinesimil   542      0       0.238197       0.039151"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in os.listdir('./dataset/test/test_2/'):\n",
    "    video_path = './dataset/test/test_2/'+file\n",
    "    id = file.replace('.mp4', '')\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = {\n",
    "        'l2':{'True': 0, 'False':0, 'conf':[]},\n",
    "        'cosine':{'True': 0, 'False':0, 'conf':[]},\n",
    "    }\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        try:\n",
    "            img = frame.copy()\n",
    "            faces = processor.preproc(img)\n",
    "\n",
    "            if len(faces)>0:\n",
    "                for face in faces:\n",
    "                    # target embeddings\n",
    "                    target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                    target = np.array(target, dtype='f')\n",
    "                    target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                    # l2\n",
    "                    neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['l2']['True'] += 1\n",
    "                        count['l2']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['l2']['False'] += 1\n",
    "\n",
    "                    # cosinesimil\n",
    "                    neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['cosine']['True'] += 1\n",
    "                        count['cosine']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['cosine']['False'] += 1\n",
    "        except:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'l2', count['l2']['True'], count['l2']['False'], np.average(count['l2']['conf']), np.std(count['l2']['conf'])]\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'cosinesimil', count['cosine']['True'], count['cosine']['False'], np.average(count['cosine']['conf']), np.std(count['cosine']['conf'])]\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.92 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(results_all['True'])/(np.sum(results_all['True'])+np.sum(results_all['False']))*100\n",
    "print('Accuracy: {:0.2f} %'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output/real_time_face_recognition/results.xlsx'\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl', mode='w') as writer:  \n",
    "    results_all.to_excel(writer, sheet_name='default', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this notebook uses video as example, this code also works if you have a webcam/video feed, which will make it 'real-time'. You just need to change the input source of `cv2.VideoCapture`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook I showed how to perform facial recognition in real time. This has many real world applications, including surveillance, smart home automatic door, etc. I hope you find this useful for your projects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8d291e76e21ac4114bb3934f79c9cd83293577e20f5f8f5d14a21fd0b06f79d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
