{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Face Recognition\n",
    "\n",
    "Let's apply all our previous knowledge into a real-time face recognition. We will try to continuously perform facial recognition on a video stream. In this example I will use an offline video as input, but in reality you can apply it using a webcam, a cctv's live camera feed, etc! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_vggface as kv\n",
    "import modules.utils as utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a FacePreprocess instance.\n",
    "from modules.FacePreprocess import FacePreprocess\n",
    "ssd_model = r'./models/ssd/deploy.prototxt.txt'\n",
    "ssd_weights = r'./models/ssd/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "processor = FacePreprocess(ssd_model, ssd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facial embedding model you want to use\n",
    "model = kv.VGGFace(\n",
    "    model='resnet50', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='avg'\n",
    ")\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our nmslib index tree\n",
    "nmslib_path = './output/large_scale_face_recognition/'\n",
    "\n",
    "# load id_list\n",
    "id_list = pd.read_csv(nmslib_path + '/IDlist.csv')\n",
    "\n",
    "# Euclidean distance\n",
    "index_l2 = nmslib.init(method='hnsw', space='l2', data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "index_l2.loadIndex(nmslib_path + 'resnet50_index_l2.bin')\n",
    "\n",
    "# Cosine similarity\n",
    "index_cos = nmslib.init(method='hnsw', space='cosinesimil', data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "index_cos.loadIndex(nmslib_path + 'resnet50_index_cos.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier evaluation, we will use a video with only one of the subjects (joy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original clip from https://youtu.be/Ia3x_X_OX58?si=aA5GdMpRGcCar2xF \n",
    "video_path = './dataset/test/test_2/joy.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture frame-by-frame\n",
    "\n",
    "We will use openCV's `VideoCapture` which will return the video frame by frame to try and recognize the person in the video. To test the accuracy, we will keep track of the predictions. We will also output a video showing the prediction results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    columns = ['count', 'irene', 'seulgi', 'wendy', 'joy', 'yeri'], \n",
    "    index = ['l2', 'cosinesimil']\n",
    ")\n",
    "results.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count` will keep track the number of predictions made, and the columns for the other subjects will count how many times where they predicted as the person in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read: https://docs.opencv.org/3.4/dd/d9e/classcv_1_1VideoWriter.html#afec93f94dc6c0b3e28f4dd153bc5a7f0 \n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean dist. `l2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 'l2'\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# setup video writer\n",
    "vid = './output/real_time_face_recognition/resnet50_l2.mp4'\n",
    "out = cv2.VideoWriter() \n",
    "out.open(vid, fourcc, 24.0, (1920, 1080), True) # frame rate, frame size (w, h) must be same as input\n",
    "\n",
    "# read video frame-by-frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        img = frame.copy()\n",
    "        faces = processor.preproc(img)\n",
    "\n",
    "        if len(faces)>0:\n",
    "            for face in faces:\n",
    "                results['count'][dist] += 1\n",
    "\n",
    "                # target embeddings\n",
    "                target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                target = np.array(target, dtype='f')\n",
    "                target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                # predict\n",
    "                neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                \n",
    "                # results\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name][dist] += 1\n",
    "\n",
    "            # add video frame\n",
    "            top, bottom, left, right = face[1][0], face[1][1], face[1][2], face[1][3]\n",
    "            cv2.putText(frame, str(name), (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 1) \n",
    "        out.write(frame)\n",
    "\n",
    "        # if you unblock this part a window will pop up and show the frames, but only works if you run with .py \n",
    "        # On jupyter notebooks the window will crash after the loop ends and you have to restart the kernel\n",
    "        # cv2.imshow(\"frame\", frame)\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine simil. `cosinesimil`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>irene</th>\n",
       "      <th>seulgi</th>\n",
       "      <th>wendy</th>\n",
       "      <th>joy</th>\n",
       "      <th>yeri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosinesimil</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count  irene  seulgi  wendy  joy  yeri\n",
       "l2             543      0       0      0  543     0\n",
       "cosinesimil    543      0       0      0  543     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = 'cosinesimil'\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# setup video writer\n",
    "vid = './output/real_time_face_recognition/resnet50_cosinesimil.mp4'\n",
    "out = cv2.VideoWriter() \n",
    "out.open(vid, fourcc, 24.0, (1920, 1080), True) # frame rate, frame size (w, h) must be same as input\n",
    "\n",
    "# read video frame-by-frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        img = frame.copy()\n",
    "        faces = processor.preproc(img)\n",
    "\n",
    "        if len(faces)>0:\n",
    "            for face in faces:\n",
    "                results['count'][dist] += 1\n",
    "\n",
    "                # target embeddings\n",
    "                target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                target = np.array(target, dtype='f')\n",
    "                target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                # predict\n",
    "                neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                \n",
    "                # results\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name][dist] += 1\n",
    "\n",
    "            # add video frame\n",
    "            top, bottom, left, right = face[1][0], face[1][1], face[1][2], face[1][3]\n",
    "            cv2.putText(frame, str(name), (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 1) \n",
    "        out.write(frame)\n",
    "\n",
    "        # if you unblock this part a window will pop up and show the frames, but only works if you run with .py \n",
    "        # On jupyter notebooks the window will crash after the loop ends and you have to restart the kernel\n",
    "        # cv2.imshow(\"frame\", frame)\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test video only contains Joy, so it looks like the prediction results are correct. Using both L2 and Cosine distance achieve similar results. Let's benchmark the other videos in the test set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.DataFrame(\n",
    "    columns = ['ID', 'Model', 'Dist.', 'True', 'False', 'Avg. Confidence', 'Std. Confidence'], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dist.</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>Avg. Confidence</th>\n",
       "      <th>Std. Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>153</td>\n",
       "      <td>101</td>\n",
       "      <td>5312.923340</td>\n",
       "      <td>818.516174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irene</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>157</td>\n",
       "      <td>97</td>\n",
       "      <td>0.269972</td>\n",
       "      <td>0.044243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>5274.891113</td>\n",
       "      <td>1034.306274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>0.039376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>5125.419434</td>\n",
       "      <td>901.174866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seulgi</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205867</td>\n",
       "      <td>0.044302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>132</td>\n",
       "      <td>75</td>\n",
       "      <td>7951.317383</td>\n",
       "      <td>1076.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wendy</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>143</td>\n",
       "      <td>64</td>\n",
       "      <td>0.341175</td>\n",
       "      <td>0.049056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>l2</td>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>5626.979492</td>\n",
       "      <td>977.520874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yeri</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>cosinesimil</td>\n",
       "      <td>382</td>\n",
       "      <td>32</td>\n",
       "      <td>0.260116</td>\n",
       "      <td>0.079599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     Model        Dist.  True  False  Avg. Confidence  \\\n",
       "0   irene  resnet50           l2   153    101      5312.923340   \n",
       "1   irene  resnet50  cosinesimil   157     97         0.269972   \n",
       "2     joy  resnet50           l2   543      0      5274.891113   \n",
       "3     joy  resnet50  cosinesimil   543      0         0.238333   \n",
       "4  seulgi  resnet50           l2   217      1      5125.419434   \n",
       "5  seulgi  resnet50  cosinesimil   216      2         0.205867   \n",
       "6   wendy  resnet50           l2   132     75      7951.317383   \n",
       "7   wendy  resnet50  cosinesimil   143     64         0.341175   \n",
       "8    yeri  resnet50           l2   310    104      5626.979492   \n",
       "9    yeri  resnet50  cosinesimil   382     32         0.260116   \n",
       "\n",
       "   Std. Confidence  \n",
       "0       818.516174  \n",
       "1         0.044243  \n",
       "2      1034.306274  \n",
       "3         0.039376  \n",
       "4       901.174866  \n",
       "5         0.044302  \n",
       "6      1076.468750  \n",
       "7         0.049056  \n",
       "8       977.520874  \n",
       "9         0.079599  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in os.listdir('./dataset/test/test_2/'):\n",
    "    video_path = './dataset/test/test_2/'+file\n",
    "    id = file.replace('.mp4', '')\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = {\n",
    "        'l2':{'True': 0, 'False':0, 'conf':[]},\n",
    "        'cosine':{'True': 0, 'False':0, 'conf':[]},\n",
    "    }\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        try:\n",
    "            img = frame.copy()\n",
    "            faces = processor.preproc(img)\n",
    "\n",
    "            if len(faces)>0:\n",
    "                for face in faces:\n",
    "                    # target embeddings\n",
    "                    target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                    target = np.array(target, dtype='f')\n",
    "                    target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                    # l2\n",
    "                    neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['l2']['True'] += 1\n",
    "                        count['l2']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['l2']['False'] += 1\n",
    "\n",
    "                    # cosinesimil\n",
    "                    neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                    name = id_list['name'][neighbors[0]]\n",
    "                    if name == id:\n",
    "                        count['cosine']['True'] += 1\n",
    "                        count['cosine']['conf'].append(distances[0])\n",
    "                    else:\n",
    "                        count['cosine']['False'] += 1\n",
    "        except:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'l2', count['l2']['True'], count['l2']['False'], np.average(count['l2']['conf']), np.std(count['l2']['conf'])]\n",
    "    results_all.loc[len(results_all)] = [id, 'resnet50', 'cosinesimil', count['cosine']['True'], count['cosine']['False'], np.average(count['cosine']['conf']), np.std(count['cosine']['conf'])]\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.45 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(results_all['True'])/(np.sum(results_all['True'])+np.sum(results_all['False']))*100\n",
    "print('Accuracy: {:0.2f} %'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output/real_time_face_recognition/results.xlsx'\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl', mode='w') as writer:  \n",
    "    results_all.to_excel(writer, sheet_name='default', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this notebook uses video as example, this code also works if you have a webcam/video feed, which will make it 'real-time'. You just need to change the input source of `cv2.VideoCapture`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook I showed how to perform facial recognition in real time. This has many real world applications, including surveillance, smart home automatic door, etc. I hope you find this useful for your projects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8d291e76e21ac4114bb3934f79c9cd83293577e20f5f8f5d14a21fd0b06f79d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
