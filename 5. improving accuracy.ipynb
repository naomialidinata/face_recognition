{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Accuracy\n",
    "\n",
    "It's not always the case that you have the perfect dataset and the perfect test subjects. Imagine a situation where you only have one picture/subject in your dataset, and you have to find the face of one person from thousands of images. The results can very quickly get messy. In this notebook, I will show a way to tackle this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_vggface as kv\n",
    "import modules.utils as utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a FacePreprocess instance.\n",
    "from modules.FacePreprocess import FacePreprocess\n",
    "ssd_model = r'./models/ssd/deploy.prototxt.txt'\n",
    "ssd_weights = r'./models/ssd/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "processor = FacePreprocess(ssd_model, ssd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facial embedding model you want to use\n",
    "model = kv.VGGFace(\n",
    "    model='resnet50', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='avg'\n",
    ")\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "5 images processed.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================\n",
    "# Compute Embeddings\n",
    "id_list = pd.DataFrame(columns=['name', 'file'])\n",
    "embeddings = []\n",
    "for id in os.listdir('./dataset/train/'):\n",
    "    folder = './dataset/train/{}/'.format(id)\n",
    "    \n",
    "    # use img_1 for every subject\n",
    "    file = 'img_1.jpg'\n",
    "    try:\n",
    "        filepath = os.path.join(folder, file)\n",
    "        processed_img = processor.preproc(cv2.imread(filepath))[0][0]\n",
    "        embedding = model.predict(utils.resize(processed_img, input_size), verbose=False)[0,:]\n",
    "\n",
    "        id_list.loc[len(id_list.index)] = [id, filepath]\n",
    "        embeddings.append(embedding)\n",
    "    except:\n",
    "        print('Failed to process/predict {}'.format(filepath))\n",
    "print('='*10 + '\\n{} images processed.'.format(len(embeddings)))\n",
    "\n",
    "# ==========================================================================\n",
    "# Initialize nmslib\n",
    "index_time_params = {'M': 15, 'indexThreadQty': 4, 'efConstruction': 100, 'post' : 0}\n",
    "\n",
    "# l2 dist.\n",
    "index_l2 = nmslib.init(\n",
    "    method = 'hnsw', # hierarchical navigable small world graph\n",
    "    space = 'l2', # euclidean\n",
    "    data_type = nmslib.DataType.DENSE_VECTOR\n",
    ") \n",
    "index_l2.addDataPointBatch(embeddings)\n",
    "index_l2.createIndex(index_time_params)\n",
    "\n",
    "# cosine simil.\n",
    "index_cos = nmslib.init(\n",
    "    method = 'hnsw', # hierarchical navigable small world graph\n",
    "    space = 'cosinesimil', # cosine\n",
    "    data_type = nmslib.DataType.DENSE_VECTOR\n",
    ") \n",
    "index_cos.addDataPointBatch(embeddings)\n",
    "index_cos.createIndex(index_time_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this model on the example for [notebook 4](4.%20real%20time%20face%20recognition.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original clip from https://youtu.be/Ia3x_X_OX58?si=aA5GdMpRGcCar2xF \n",
    "video_path = './dataset/test/test_2/joy.mp4'\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    columns = ['count', 'irene', 'seulgi', 'wendy', 'joy', 'yeri'], \n",
    "    index = ['l2', 'cosinesimil']\n",
    ")\n",
    "results.fillna(0, inplace=True)\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# read video frame-by-frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        img = frame.copy()\n",
    "        faces = processor.preproc(img)\n",
    "\n",
    "        if len(faces)>0:\n",
    "            for face in faces:\n",
    "                results['count']['l2'] += 1\n",
    "                results['count']['cosinesimil'] += 1\n",
    "\n",
    "\n",
    "                # target embeddings\n",
    "                target = model.predict(utils.resize(face[0], input_size), verbose=False)[0,:]\n",
    "                target = np.array(target, dtype='f')\n",
    "                target = np.expand_dims(target, axis=0)\n",
    "\n",
    "                # l2\n",
    "                neighbors, distances = index_l2.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name]['l2'] += 1\n",
    "\n",
    "                # cosinesimil\n",
    "                neighbors, distances = index_cos.knnQueryBatch(target, k=1, num_threads=4)[0]\n",
    "                name = id_list['name'][neighbors[0]]\n",
    "                results[name]['cosinesimil'] += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>irene</th>\n",
       "      <th>seulgi</th>\n",
       "      <th>wendy</th>\n",
       "      <th>joy</th>\n",
       "      <th>yeri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosinesimil</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count  irene  seulgi  wendy  joy  yeri\n",
       "l2             543      0       0      0  540     3\n",
       "cosinesimil    543      0       0      0  542     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with only one image/subject, the accuracy isn't as great. In this case we only have 5 subjects in our dataset, so the results aren't as bad. But when you have more people in your dataset, the results will only get worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Double verification\n",
    "\n",
    "For this method, we will use both distance models at once. If both models return the same ID, we'll add it to the tally, otherwise we'll count it as unknown.\n",
    "\n",
    "![fig](./assets/fig3.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DV = pd.DataFrame(\n",
    "    columns = ['unknown', 'irene', 'seulgi', 'wendy', 'joy', 'yeri'], \n",
    "    \n",
    ")\n",
    "results_DV.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown</th>\n",
       "      <th>irene</th>\n",
       "      <th>seulgi</th>\n",
       "      <th>wendy</th>\n",
       "      <th>joy</th>\n",
       "      <th>yeri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [unknown, irene, seulgi, wendy, joy, yeri]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_DV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8d291e76e21ac4114bb3934f79c9cd83293577e20f5f8f5d14a21fd0b06f79d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
