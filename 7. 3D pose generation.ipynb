{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Pose Generation\n",
    "\n",
    "With `NextFace`, we can generate a face with various poses from a single image. This is useful when we want to expand our database, in cases where we only have a single image/subject.\n",
    "\n",
    "For more details, check out their [repository](https://github.com/abdallahdib/NextFace)!\n",
    "\n",
    "> Disclaimer: This is simply a tutorial on how to use `NextFace`. I do not claim to own any of the code or trained models in `./models/`, I simply modified their code to fit my needs and this repository, and some I updated so it can run with up-to-date libraries. All credit goes to the original repository, so please cite and give them a star!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, you need a different working environment from the previous notebooks. For the installation guide, please refer [here](https://github.com/abdallahdib/NextFace/blob/main/INSTALL).\n",
    "\n",
    "Or, in your Anaconda Prompt, run these commands\n",
    "\n",
    "    conda create --name faceNext python=3.8\n",
    "    conda activate faceNext\n",
    "    pip install redner-gpu\n",
    "    pip install --upgrade pip setuptools wheel --user\n",
    "    pip install opencv-python==4.5.5.64\n",
    "    pip install mediapipe\n",
    "    conda install -c 1adrianb face_alignment=1.2.0\n",
    "    conda install -c anaconda h5py\n",
    "    pip install ipykernel\n",
    "\n",
    "Finally, install the [pytorch](https://pytorch.org/) version that's compatible with your OS and devices. \n",
    "\n",
    "> Disclaimer: if possible, please follow the instructions on the original repository, but they don't work for me, and this is what ends up working for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.NextFace.optimizer import Optimizer\n",
    "from models.NextFace.config import Config\n",
    "from models.NextFace.utils import *\n",
    "from models.NextFace.image import saveImage\n",
    "import math\n",
    "import json\n",
    "import mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will try to convert `./dataset/train/joy/img_1.jpg`. Let's set the input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './dataset/train/joy/img_1.jpg'\n",
    "output_path = './output/3D_pose_generation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Optimize\n",
    "\n",
    "Remember to configure your device in `./models/NextFace/optimConfig.ini`. If you're using GPU, please change the device to `'cuda'`. For better results, make sure that `MediaPipe` is installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './models/NextFace/optimConfig.ini'\n",
    "config = Config()\n",
    "config.fillFromDicFile(config_path)\n",
    "\n",
    "if config.device == 'cuda' and torch.cuda.is_available() == False:\n",
    "    print('[WARN] no cuda enabled device found. switching to cpu... ')\n",
    "    config.device = 'cpu'\n",
    "if config.lamdmarksDetectorType == 'mediapipe':\n",
    "    try:\n",
    "        from models.NextFace.landmarksmediapipe import LandmarksDetectorMediapipe\n",
    "    except:\n",
    "        print('[WARN] Mediapipe for landmarks detection not availble. falling back to FAN landmarks detector. You may want to try Mediapipe because it is much accurate than FAN (pip install mediapipe)')\n",
    "        config.lamdmarksDetectorType = 'fan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedIdentity = None\n",
    "checkpoint = ''\n",
    "doStep1 = True\n",
    "doStep2 = True\n",
    "doStep3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(outputDir=output_path, config=config)\n",
    "optimizer.run(\n",
    "    input_path, \n",
    "    sharedIdentity= sharedIdentity,\n",
    "    checkpoint= checkpoint,\n",
    "    doStep1= doStep1,\n",
    "    doStep2 = doStep2,\n",
    "    doStep3= doStep3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 ('facenext')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ef1ad61b00f85b47f03ec5ff94a78b1355301673b51d0b04abd0cc912f041d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
