{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Face recognition\n",
    "\n",
    "What if your dataset contains thousands of identities, with thousands of pictures for each of them? It will be impossible to compare their embeddings one-by-one to find the closest match. This notebook will show you how to use `NMSLIB`, a similarity search library based on approximate nearest neighbors (ANN).\n",
    "\n",
    "source: https://github.com/nmslib/nmslib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_vggface as kv\n",
    "import modules.utils as utils\n",
    "from tensorflow.keras.models import save_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from statistics import mean\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a FacePreprocess instance.\n",
    "from modules.FacePreprocess import FacePreprocess\n",
    "ssd_model = r'./models/ssd/deploy.prototxt.txt'\n",
    "ssd_weights = r'./models/ssd/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "processor = FacePreprocess(ssd_model, ssd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facial embedding model you want to use\n",
    "model = kv.VGGFace(\n",
    "    model='resnet50', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='avg'\n",
    ")\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embeddings\n",
    "\n",
    "Since we want to build a tree using the facial embeddings, let's compute embeddings of all the images in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "25 images processed.\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for id in os.listdir('./dataset/train/'):\n",
    "    folder = './dataset/train/{}/'.format(id)\n",
    "    for file in os.listdir(folder):\n",
    "        try:\n",
    "            filepath = os.path.join(folder, file)\n",
    "            processed_img = processor.preproc(cv2.imread(filepath))[0][0]\n",
    "            embedding = model.predict(utils.resize(processed_img, input_size), verbose=False)[0,:]\n",
    "\n",
    "            embeddings.append([id, embedding])\n",
    "        except:\n",
    "            print('Failed to process/predict {}'.format(filepath))\n",
    "print('='*10 + '\\n{} images processed.'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8d291e76e21ac4114bb3934f79c9cd83293577e20f5f8f5d14a21fd0b06f79d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
